{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "62882f0d-8214-4bf8-8fde-c7bbd5e7cca7",
   "metadata": {},
   "source": [
    "# Preprocessing Pipeline for Structural Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "279bc4b0-9a12-4949-8bec-b38bb68466bc",
   "metadata": {},
   "source": [
    "- Sections:\n",
    "    - Set-up: Run every time to create input dictionary\n",
    "    - Part 1:\n",
    "    - Part 2:\n",
    "    - Part 3:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4ae7824-79ee-48a2-a1a5-8239f63379f0",
   "metadata": {},
   "source": [
    "# Set-Up: \n",
    "## Select Subjects to Process and Set Variables - This sections needs to be run before each of the 3 Parts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1faf96b-6ceb-4387-9eb5-1048b2b086fe",
   "metadata": {},
   "source": [
    "### Packages and Functions Needed for This Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d6d7766-fe1c-4e5b-b9e5-b1e352fdbf6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from glob import glob\n",
    "from nilearn import plotting\n",
    "import subprocess\n",
    "import sys\n",
    "import matplotlib_inline\n",
    "from tqdm import tqdm\n",
    "import tempfile\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "# export MPLBACKEND=TkAgg "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "38040f25-9805-448a-aad4-a4a927c212bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def submit_slurm_job(job_name, command, partition=\"bch-compute\", nodes=1, cpus_per_task=16, mem=\"50G\", time=\"24:00:00\"):\n",
    "    \n",
    "    script = f\"\"\"#!/bin/bash\n",
    "        #SBATCH --job-name={job_name}\n",
    "        #SBATCH --partition={partition}\n",
    "        #SBATCH --nodes={nodes}\n",
    "        #SBATCH --cpus-per-task={cpus_per_task}\n",
    "        #SBATCH --mem={mem}\n",
    "        #SBATCH --time={time}\n",
    "\n",
    "        # Run the command\n",
    "        export MPLBACKEND=TkAgg\n",
    "        \n",
    "        {command}\n",
    "        \"\"\"\n",
    "    \n",
    "    # Write the script to a temporary file\n",
    "    with tempfile.NamedTemporaryFile(mode='w', delete=False) as f:\n",
    "        f.write(script)\n",
    "        script_file = f.name\n",
    "\n",
    "    # Make the script executable\n",
    "    subprocess.run([\"chmod\", \"+x\", script_file])\n",
    "\n",
    "    try:\n",
    "        # Submit the job using sbatch through the shell\n",
    "        output = subprocess.check_output(['sbatch', script_file]).decode('utf-8')\n",
    "\n",
    "        # Extract the job ID from the output\n",
    "        job_id = output.strip().split()[-1]\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"Error submitting job: {e}\")\n",
    "        job_id = None\n",
    "\n",
    "    return job_id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6424c527-7a6b-4f6e-9c92-cc1c4389e281",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_input_dict(input_folder, subjects_to_skip=None, input_type='FOLDER'):\n",
    "    # Check if input_folder is a valid directory\n",
    "    if not Path(input_folder).is_dir():\n",
    "        raise ValueError(\"Input folder is not a valid directory\")\n",
    "    \n",
    "    subject_sessions = {}\n",
    "    \n",
    "    if input_type=='BIDS':\n",
    "        subjects=[f for f in os.listdir(input_dir) if os.path.isdir(os.path.join(input_dir, f))]\n",
    "        \n",
    "        if subjects_to_skip is not None:\n",
    "            subjects = [subject for subject in subjects if subject not in subjects_to_skip]\n",
    "            \n",
    "        print(\"There are\", len(subjects), \"unique subjects to be registered\")\n",
    "        \n",
    "        for subject in sorted(subjects):\n",
    "            # Get the path to the subject folder\n",
    "            subject_path = os.path.join(input_dir, subject)\n",
    "\n",
    "            # Get a list of session folders within the subject folder\n",
    "            sessions = [f for f in os.listdir(subject_path) if os.path.isdir(os.path.join(subject_path, f))]\n",
    "\n",
    "            # Add the subject and sessions to the dictionary\n",
    "            subject_sessions[subject] = sessions\n",
    "\n",
    "\n",
    "        print(subject_sessions)\n",
    "        \n",
    "    \n",
    "    elif input_type=='FOLDER':\n",
    "        #All selected scans are in one folder\n",
    "        #Assumptions: first part of file name is subject ID followed by an _\n",
    "        subjects=sorted(set([os.path.basename(i).split('_')[0] for i in glob(f'{input_dir}/*.nii*')]))\n",
    "        \n",
    "        if subjects_to_skip is not None:\n",
    "            subjects = [subject for subject in subjects if subject not in subjects_to_skip]\n",
    "            \n",
    "        print(\"There are\", len(subjects), \"unique subjects to be registered\")\n",
    "        \n",
    "        \n",
    "        for subject in sorted(subjects):\n",
    "            for file in glob(f'{input_dir}/*{subject}*.nii*'):\n",
    "                subject = os.path.basename(file).split('_')[0]\n",
    "                session = os.path.basename(file).split('_')[1]\n",
    "\n",
    "                if subject not in subject_sessions:\n",
    "                    subject_sessions[subject] = []\n",
    "                if session not in subject_sessions[subject]:  \n",
    "                    subject_sessions[subject].append(session)\n",
    "\n",
    "\n",
    "        print(subject_sessions)\n",
    "\n",
    "    \n",
    "    else:\n",
    "        raise ValueError(f\"Invalid input_type: '{input_type}'. Should be either 'BIDS' or 'FOLDER'.\")\n",
    "    \n",
    "    \n",
    "    return subject_sessions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56726836-88e5-469b-9a2b-92b794a833bc",
   "metadata": {},
   "source": [
    "### Put your information below then create the input dictionary (subject_sessions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e1a65641-f5c9-4b4b-a3e8-f6b7036dc0a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir=\"test_input_combine\"  #Folder with input files\n",
    "#input_dir = '/lab-share/Neuro-Cohen-e2/Public/lesions/RDCRN_TSC/'\n",
    "\n",
    "input_type='BIDS' #'BIDS' or 'Folder'\n",
    "subjects_to_skip=['sub-MGH083']  \n",
    "\n",
    "\n",
    "output_dir=\"output_combine_test\"\n",
    "\n",
    "\n",
    "IMAGE_TYPES = ['T1w', 'T2w', 'FLAIR'] #case sensitive, change to match what you used e.g. t1, t1w, TI \n",
    "Reg_target_1='T1w' #your ideal registration target, case sensitive\n",
    "Reg_target_2='T2w' #your second choice for registration target, case sensitive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4460d857-8920-4d95-94fc-b68711883cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir=\"RDCRN_test\"  #Folder with input files\n",
    "input_type='BIDS' #'BIDS' or 'Folder'\n",
    "#input_dir = '/lab-share/Neuro-Cohen-e2/Public/lesions/RDCRN_TSC/'\n",
    "output_dir=\"output_RDCDN_test_new_2\"\n",
    "\n",
    "\n",
    "IMAGE_TYPES = ['t1', 't2'] #case sensitive, change to match what you used e.g. t1, t1w, TI \n",
    "Reg_target_1='t1' #your ideal registration target, case sensitive\n",
    "Reg_target_2='t2' #your second choice for registration target, case sensitive\n",
    "\n",
    "#Bias correction only works on T1 or T2, bias correction is set to work on the registration target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e2a9578b-4349-4bc9-a342-fec1ed3416c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 2 unique subjects to be registered\n",
      "{'7901-01-001': ['scan01', 'scan03', 'scan02'], '7901-01-002': ['scan01', 'scan02']}\n"
     ]
    }
   ],
   "source": [
    "subject_sessions=create_input_dict(input_dir, input_type='BIDS')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "824b32ef-fcee-458d-bf74-e9c7ca485dba",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Part 1: Make Output Folders and Combine Images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7215de6a-5625-4741-aba0-db34364954c1",
   "metadata": {},
   "source": [
    "## Part 1 Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "682ba1f0-c3c3-4621-b253-12f64dc74e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_tree(d, n=5, indent=0):\n",
    "    \"\"\"\n",
    "    Recursively prints the folder structure.\n",
    "    \n",
    "    Parameters:\n",
    "    d (dict): The folder structure dictionary.\n",
    "    indent (int): The indentation level (number of spaces).\n",
    "    \"\"\"\n",
    "    \n",
    "    subset = {k: subject_sessions[k] for k in list(subject_sessions)[:n]}\n",
    "    \n",
    "    for key, value in subset.items():\n",
    "        print('    ' * indent + str(key))\n",
    "        if isinstance(value, list):\n",
    "            for item in value:\n",
    "                print('    ' * (indent + 1) + str(item))\n",
    "        elif isinstance(value, dict):\n",
    "            print_tree(value, indent + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5546dff2-6cd4-4d1a-a359-ff5e4cd4ad48",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def combine_images(working_dir, participant, session, image_type, list_of_images, clean_up=True):\n",
    "    \n",
    "    BIDSPATH = '/lab-share/Neuro-Cohen-e2/Public/lesions/MGH_Perinatal_Stroke_BIDS/code/bids_lesion_code'\n",
    "   \n",
    "    \n",
    "    for i, image in enumerate(list_of_images, start=1):\n",
    "        mask_file = f'{working_dir}/temp_{i}_{image_type}_mask.nii.gz'\n",
    "        \n",
    "\n",
    "        result = subprocess.run(['fslmaths', image, '-abs', '-bin', mask_file], stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "        if result.returncode != 0:\n",
    "            print(result.stderr.decode())\n",
    "            raise Exception(f'Failed to create mask for {image}')\n",
    "        \n",
    "    \n",
    "    mask_files = [f'/app/data/temp_{i}_{image_type}_mask.nii.gz' for i in range(1, len(list_of_images) + 1)]\n",
    "    output_file = f'/app/data/{participant}_{session}_{image_type}.nii.gz'\n",
    "    \n",
    "    cmd = [\n",
    "        'singularity', 'exec',\n",
    "        '-B', f'{working_dir}:/app/data',\n",
    "        '-B', f'{BIDSPATH}:{BIDSPATH}',\n",
    "        f'{BIDSPATH}/niftymic.sif',\n",
    "        'niftymic_reconstruct_volume',\n",
    "        '--filenames', *list_of_images,\n",
    "        '--filenames-masks', *mask_files,\n",
    "        '--output', output_file\n",
    "    ]\n",
    "    \n",
    "    if clean_up == True:\n",
    "            cmd += [\n",
    "            'rm', '-r', \n",
    "            f'{working_dir}/config*', \n",
    "            f'{working_dir}/temp*', \n",
    "            f'{working_dir}/*mask*', \n",
    "            f'{working_dir}/motion_correction'\n",
    "        ]\n",
    "        \n",
    "    command = ' '.join(cmd)\n",
    "\n",
    "    return command\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db710cf2-b69d-4fe0-8716-d7b874568c1c",
   "metadata": {},
   "source": [
    "### Part 1a : Make output folder system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "361fe04c-9d1c-4b4f-ba7e-5f7c32da5bd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your output folder system will look something like this: \n",
      "7901-01-001\n",
      "    scan01\n",
      "    scan03\n",
      "    scan02\n",
      "7901-01-002\n",
      "    scan01\n",
      "    scan02\n"
     ]
    }
   ],
   "source": [
    "print(f'Your output folder system will look something like this: ')\n",
    "print_tree(subject_sessions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1978c62c-df4a-4594-bb8c-1f2687d999b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing scan01 for 7901-01-001\n",
      "Processing scan02 for 7901-01-001\n",
      "Processing scan03 for 7901-01-001\n",
      "Processing scan01 for 7901-01-002\n",
      "Processing scan02 for 7901-01-002\n"
     ]
    }
   ],
   "source": [
    "combine_dict={}\n",
    "for subject, sessions in subject_sessions.items():\n",
    "    subject_folder = os.path.join(output_dir, subject)\n",
    "    if not os.path.exists(subject_folder):\n",
    "        os.makedirs(subject_folder)\n",
    "    \n",
    "    for session in sorted(set(sessions)):\n",
    "        print(f'Processing {session} for {subject}')\n",
    "        session_folder = os.path.join(subject_folder, session)\n",
    "         \n",
    "        \n",
    "        if os.path.exists(session_folder):\n",
    "            if os.listdir(session_folder):\n",
    "                print(f\"{subject}: {session_folder} exists and is not empty\")\n",
    "        else:\n",
    "            if not os.path.exists(session_folder):\n",
    "                os.makedirs(session_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "872969d8-edc1-41c5-b968-e8fcea9565f6",
   "metadata": {},
   "source": [
    "### Part 1b: copy selected files to output folder system, combine images as needed (will submit to SLURM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "47be069d-7e72-4f49-b85d-197dd5ea841b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: A file with image type 't1' already exists in output_RDCDN_test_new_2/7901-01-001/scan01\n",
      "Error: A file with image type 't2' already exists in output_RDCDN_test_new_2/7901-01-001/scan01\n",
      "Error: A file with image type 't1' already exists in output_RDCDN_test_new_2/7901-01-001/scan02\n",
      "Error: A file with image type 't2' already exists in output_RDCDN_test_new_2/7901-01-001/scan02\n",
      "Error: A file with image type 't1' already exists in output_RDCDN_test_new_2/7901-01-001/scan03\n",
      "Error: A file with image type 't2' already exists in output_RDCDN_test_new_2/7901-01-001/scan03\n",
      "Error: A file with image type 't1' already exists in output_RDCDN_test_new_2/7901-01-002/scan01\n",
      "Error: A file with image type 't2' already exists in output_RDCDN_test_new_2/7901-01-002/scan01\n",
      "Error: A file with image type 't1' already exists in output_RDCDN_test_new_2/7901-01-002/scan02\n",
      "Error: A file with image type 't2' already exists in output_RDCDN_test_new_2/7901-01-002/scan02\n",
      "You have 0 Combine Jobs\n"
     ]
    }
   ],
   "source": [
    "combine_dict={}\n",
    "for subject, sessions in subject_sessions.items():\n",
    "    subject_folder = os.path.join(output_dir, subject)\n",
    "\n",
    "    for session in sorted(set(sessions)):\n",
    "        session_folder = os.path.join(subject_folder, session)\n",
    "         \n",
    "        for image_type in IMAGE_TYPES:\n",
    "\n",
    "            if glob(f'{session_folder}/*{image_type}*.nii*'):\n",
    "                    print(f\"Error: A file with image type '{image_type}' already exists in {session_folder}\")\n",
    "            else:    \n",
    "                if input_type == 'FOLDER':\n",
    "                    images = glob(f'{input_dir}/{subject}*{session}*{image_type}*.nii*')\n",
    "                elif input_type == 'BIDS':\n",
    "                    images = glob(f'{input_dir}/{subject}/{session}/*{image_type}*.nii*')\n",
    "             \n",
    "                if len(images) > 3:\n",
    "                    print(f\"Error: More than 3 images found for participant {subject}, session {session}, and image type {image_type}.\")\n",
    "                    continue\n",
    "                if len(images) > 1:\n",
    "                    print(f\"combining: {images}\")\n",
    "                    command = combine_images(session_folder, subject, session, image_type, images, clean_up=True)\n",
    "                    job_name = f\"combine_images_{subject}_{session}_{image_type}\"\n",
    "                    job_id=submit_slurm_job(job_name, command)\n",
    "                    combine_dict[(subject,session)] = job_id\n",
    "                elif len(images) == 1:\n",
    "                    print(f\"moving: {images} to {session_folder}/{subject}_{session}_{image_type}.nii.gz\")\n",
    "                    shutil.copy(images[0], f'{session_folder}/{subject}_{session}_{image_type}.nii.gz')\n",
    "\n",
    "if len(combine_dict) > 0:\n",
    "    print('You have', len(combine_dict), 'Combine Jobs submitted to SLURM; subject and job IDs are stored in combine_dict')\n",
    "    print('You can type \"squeue -u $USER\" into your terminal to track SLURM job progress')\n",
    "    print('You can check the output file matching the jobid in combine_dict to see code outputs and any errors\")\n",
    "else:\n",
    "    print('You have', len(combine_dict), 'Combine Jobs')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b33f006-7099-4ed1-9948-52db4d1bc3a2",
   "metadata": {},
   "source": [
    "# Part 2: Prepare Registration Images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3417a52d-5ed3-4f8b-bf9d-3df2bf9dbb83",
   "metadata": {},
   "source": [
    "## Part 2 Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3f88e9d9-f100-42dd-8c97-e7df25cd48f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_registration_target(file_names):\n",
    "    global Reg_target_1\n",
    "    global Reg_target_2\n",
    "    reg_target = None\n",
    "    for file_name in file_names:\n",
    "        if Reg_target_1 in file_name:\n",
    "            reg_target = Reg_target_1\n",
    "            break\n",
    "    if reg_target is None:\n",
    "        for file_name in file_names:\n",
    "            if Reg_target_2 in file_name:\n",
    "                reg_target = Reg_target_2\n",
    "                break\n",
    "    if reg_target is None:\n",
    "        raise ValueError(f\"No registration target found in {file_names}\")\n",
    "    return reg_target\n",
    "\n",
    "    \n",
    "def reslice_image(input_folder, participant, session, reg_target):\n",
    "    filename=f'{input_folder}/{participant}_{session}_{reg_target}.nii.gz'\n",
    "    if not os.path.exists(filename):\n",
    "        raise FileNotFoundError(f\"File {filename} does not exist\")\n",
    "    # Get the maximum pixel width\n",
    "    cmd = f\"fslinfo {filename} | grep pixdim[1-3] | awk '{{ print $2 }}' | sort -rn | head -1\"\n",
    "    max_pixelwidth = float(subprocess.check_output(cmd, shell=True).strip())\n",
    "\n",
    "    if max_pixelwidth > 1.5:\n",
    "        print(f\"Largest pixel dimension is {max_pixelwidth} > 1.5mm, reslicing to 1mm isovolumetric\")\n",
    "        \n",
    "        input_file = f\"{input_folder}/{participant}_{session}_{reg_target}.nii.gz\"\n",
    "        size = 1\n",
    "        output_file = f\"{input_folder}/{participant}_{session}_{reg_target}_{size}mm.nii.gz\"\n",
    "\n",
    "        cmd = f\"flirt -interp spline -in {input_file} -ref {input_file} -applyisoxfm {size} -out {output_file}\"\n",
    "        subprocess.run(cmd, shell=True)\n",
    "\n",
    "        os.rename(input_file, f\"{input_folder}/{participant}_{session}_{reg_target}_aniso.nii.gz\")\n",
    "        os.rename(output_file, input_file)\n",
    "    else:\n",
    "        print(f\"Largest pixel dimension is {max_pixelwidth}, leaving image alone\")\n",
    "        \n",
    "\n",
    "def bias_corr(input_folder, participant, session, reg_target, clean_up=True):\n",
    "    stem = f'{input_folder}/{participant}_{session}_{reg_target}' \n",
    "    \n",
    "    if os.path.exists(f\"{stem}_orig.nii.gz\"):\n",
    "        print(f'{stem}_orig.nii.gz already exists, suggesting this image has been bias corrected already!')\n",
    "        return\n",
    "    \n",
    "    if '1' in reg_target:\n",
    "        img_type='T1'\n",
    "    elif '2' in reg_target:\n",
    "        img_type='T2'\n",
    "        \n",
    "    # Run fsl_anat_alt.sh\n",
    "    cmd = f\"./fsl_anat_alt.sh -i {stem} -t {img_type} --noreg --nosubcortseg --noseg\"\n",
    "\n",
    "        # Rename files\n",
    "    cmd += f\"mv {input_folder}/{participant}_{session}_{reg_target}.nii.gz {stem}_orig.nii.gz\\n\"\n",
    "    cmd += f\"mv {stem}.anat/T1_biascorr.nii.gz {stem}.nii.gz\\n\"\n",
    "\n",
    "    # Run fslmaths\n",
    "    cmd += f\"fslmaths {stem}.nii.gz {stem}.nii.gz -odt short\"\n",
    "    \n",
    "    if clean_up == True:\n",
    "        cmd += f\"rm -r {stem}.anat\"\n",
    "        \n",
    "    return cmd\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17fa154f-c056-4d37-97a5-8bb54df31aa2",
   "metadata": {},
   "source": [
    "### Run Part 2; will submit jobs to SLURM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b7a8da70-3ef1-4ca7-8a1e-b86819b7c917",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Processing 7901-01-001: scan01 ***\n",
      "t1\n",
      "Reslicing t1\n",
      "Largest pixel dimension is 1.0, leaving image alone\n",
      "Bias Correcting t1\n",
      "*** Processing 7901-01-001: scan03 ***\n",
      "t1\n",
      "Reslicing t1\n",
      "Largest pixel dimension is 1.0, leaving image alone\n",
      "Bias Correcting t1\n",
      "*** Processing 7901-01-001: scan02 ***\n",
      "t1\n",
      "Reslicing t1\n",
      "Largest pixel dimension is 1.0, leaving image alone\n",
      "Bias Correcting t1\n",
      "*** Processing 7901-01-002: scan01 ***\n",
      "t1\n",
      "Reslicing t1\n",
      "Largest pixel dimension is 1.0, leaving image alone\n",
      "Bias Correcting t1\n",
      "*** Processing 7901-01-002: scan02 ***\n",
      "t1\n",
      "Reslicing t1\n",
      "Largest pixel dimension is 1.0, leaving image alone\n",
      "Bias Correcting t1\n",
      "You have 5 Bias Correction Jobs submitted to SLURM; subject and job IDs are stored in bias_corr_dict\n",
      "You can type \"squeue -u $USER\" into your terminal to track SLURM job progress\n",
      "You can check the output file matching the jobid in bias_corr_dict to see code outputs and any errors\n"
     ]
    }
   ],
   "source": [
    "bias_corr_dict={}\n",
    "for subject, sessions in subject_sessions.items():\n",
    "    reg_target=None\n",
    "    subject_folder = os.path.join(output_dir, subject) \n",
    "    for session in sessions:\n",
    "        print(f'*** Processing {subject}: {session} ***')\n",
    "        session_folder=os.path.join(subject_folder, session)\n",
    "        \n",
    "        reg_target=set_registration_target(glob(f'{session_folder}/*.nii*'))\n",
    "        print(reg_target)\n",
    "        \n",
    "        print(f'Reslicing {reg_target}')\n",
    "        reslice_image(session_folder, subject, session, reg_target)\n",
    "        \n",
    "        print(f'Bias Correcting {reg_target}')\n",
    "        command=bias_corr(session_folder, subject, session, reg_target, clean_up=True) \n",
    "        job_name = f\"bias_correct_{subject}_{session}_{reg_target}\"\n",
    "        job_id=submit_slurm_job(job_name, command)\n",
    "        bias_corr_dict[(subject,session)] = job_id\n",
    "\n",
    "if len(bias_corr_dict) > 0:\n",
    "    print('You have', len(bias_corr_dict), 'Bias Correction Jobs submitted to SLURM; subject and job IDs are stored in bias_corr_dict')\n",
    "    print('You can type \"squeue -u $USER\" into your terminal to track SLURM job progress')\n",
    "    print('You can check the output file matching the jobid in bias_corr_dict to see code outputs and any errors')\n",
    "else:\n",
    "    print('You have', len(bias_corr_dict), 'Bias Correction Jobs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d7c59d25-8754-4a8e-813a-d92e9a3f0bd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             JOBID PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON)\n",
      "            691069 bch-inter     bash ch236393  R    3:53:20      1 compute-10-13\n"
     ]
    }
   ],
   "source": [
    "!squeue -u $USER"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34fdb466-f65c-406e-a5ed-11d91b87103c",
   "metadata": {},
   "source": [
    "# Part 3: Co-Register and Skull Strip Images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9522ce50-96ad-42e8-ae95-9989600acc5e",
   "metadata": {},
   "source": [
    "## Part 3 Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6d3f6181-5a32-40ad-b715-46afb4a61659",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Co-register files to the Registration Target\n",
    "#consider using logging\n",
    "def set_registration_target(file_names):\n",
    "    global Reg_target_1\n",
    "    global Reg_target_2\n",
    "    reg_target = None\n",
    "    for file_name in file_names:\n",
    "        if Reg_target_1 in file_name:\n",
    "            reg_target = Reg_target_1\n",
    "            break\n",
    "    if reg_target is None:\n",
    "        for file_name in file_names:\n",
    "            if Reg_target_2 in file_name:\n",
    "                reg_target = Reg_target_2\n",
    "                break\n",
    "    if reg_target is None:\n",
    "        raise ValueError(f\"No registration target found in {file_names}\")\n",
    "    return reg_target\n",
    "\n",
    "def co_register(working_dir, reg_image, moving_image, skullstrip=True, clean_up=True):\n",
    "    \n",
    "    if not os.path.exists(f'{working_dir}/warps'):\n",
    "        os.makedirs(f'{working_dir}/warps')\n",
    "    \n",
    "    moving_stem=os.path.basename(moving_image).split('.')[0]\n",
    "    \n",
    "    if os.path.exists(f\"{working_dir}/{moving_stem}_space-{reg_target}.nii.gz\"):\n",
    "        print(f\"WARNING: Input image file {moving_stem}_space-{reg_target}.nii.gz already exists. Skipping...\")\n",
    "        return \n",
    "    \n",
    "    cmd = f\"conda run -n nimlab_py310_2023_11 antsRegistrationSyNQuick.sh -d 3 -m {moving_image} -f {reg_image} -t sr -o {working_dir}/warps/{moving_stem}_space-{reg_target}\"\n",
    "    \n",
    "    cmd +=f\"mv {working_dir}/warps/{moving_stem}_space-{reg_target}Warped.nii.gz {working_dir}/{moving_stem}_space-{reg_target}.nii.gz\"\n",
    "    \n",
    "    if clean_up == True:\n",
    "        cmd +=f\" rm -r {working_dir}/warps\"\n",
    "        \n",
    "    \n",
    "    if skullstrip=True:\n",
    "        filename=f'{moving_stem}_space-{reg_target}'\n",
    "        out_file=f'{session_folder}/COREGISTERED/{filename}_SkullStripped.nii.gz'\n",
    "        out_mask=f'{session_folder}/COREGISTERED/{filename}_brain-mask.nii.gz'\n",
    "        cmd += f'mri_synthstrip -i {file} -o {out_file} -m {out_mask}'\n",
    "       \n",
    "        \n",
    "    # try:\n",
    "    #     output = subprocess.run(cmd, shell=True, check=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "    # except subprocess.CalledProcessError as e:\n",
    "    #     print(f\"Error: command '{e.cmd}' failed with exit code {e.returncode}\")\n",
    "    #     print(f\"Output: {e.output.decode('utf-8')}\")\n",
    "    #     print(f\"Error message: {e.stderr.decode('utf-8')}\")\n",
    "    #     return\n",
    "        \n",
    "    return cmd\n",
    "        \n",
    "    # remove non-BIDS suffix\n",
    "    # src = f\"{working_dir}/warps/{moving_stem}_space-{reg_target}Warped.nii.gz\"\n",
    "    # dst = f\"{working_dir}/{moving_stem}_space-{reg_target}.nii.gz\"\n",
    "    # os.rename(src, dst)\n",
    "    \n",
    "    # shutil.rmtree(f'{working_dir}/warps/')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43621f5a-8539-4db6-a583-52e17cb70fa7",
   "metadata": {},
   "source": [
    "### Run Part 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d0ad644-0287-402d-b403-7468ee14eb9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "co_reg_dict={}\n",
    "for subject, sessions in subject_sessions.items():\n",
    "    reg_target=None\n",
    "    subject_folder = os.path.join(output_dir, subject) \n",
    "    for session in sessions:\n",
    "        print(f'*** Processing {subject}: {session} ***')\n",
    "        session_folder=os.path.join(subject_folder, session)\n",
    "        \n",
    "        reg_target=set_registration_target(glob(f'{session_folder}/*.nii*'))\n",
    "        print(reg_target)\n",
    "        \n",
    "        print(f'Registering Images to the {reg_target}') #~5 min per file\n",
    "        if not os.path.exists(f'{session_folder}/COREGISTERED'):\n",
    "            os.makedirs(f'{session_folder}/COREGISTERED')\n",
    "        reg_file=f'{session_folder}/{subject}_{session}_{reg_target}.nii.gz'\n",
    "        for file in glob(f'{session_folder}/*.nii*'):\n",
    "        #for file in tqdm(glob(f'{session_folder}/*.nii*'), desc='Registering images'):\n",
    "                if reg_target not in file:\n",
    "                    print(f'Regestering {file}')\n",
    "                    command=co_register(f'{session_folder}/COREGISTERED', reg_file, file, skullstrip=True)\n",
    "                    job_name = f\"co-register_{subject}_{session}_{reg_target}\"\n",
    "                    job_id=submit_slurm_job(job_name, command)\n",
    "                    co_reg_dict[(subject,session)] = job_id\n",
    "\n",
    "if len(co_reg_dict) > 0:\n",
    "    print('You have', len(co_reg_dict), 'Co-Registration Jobs submitted to SLURM; subject and job IDs are stored in the co_reg_dict')\n",
    "    print('You can type \"squeue -u $USER\" into your terminal to track SLURM job progress')\n",
    "    print('You can check the output file matching the jobid in co_reg_dict to see code outputs and any errors\")\n",
    "                                     \n",
    "        \n",
    "#         #Skull Strip\n",
    "#         for file in glob(f'{session_folder}/COREGISTERED/*.nii*'):\n",
    "#             filename=os.path.basename(file).split('.')[0]\n",
    "#             out_file=f'{session_folder}/COREGISTERED/{filename}_SkullStripped.nii.gz'\n",
    "#             out_mask=f'{session_folder}/COREGISTERED/{filename}_brain-mask.nii.gz'\n",
    "#             command = f'mri_synthstrip -i {file} -o {out_file} -m {out_mask}'\n",
    "            \n",
    "#             print(f\"Processing file: {file}\")\n",
    "#             try:\n",
    "#                 subprocess.run(command, shell=True, check=True)\n",
    "#             except subprocess.CalledProcessError as e:\n",
    "#                 print(f\"Error running mri_synthstrip: {e}\")\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f9323f8-32ff-4062-bf09-9afce3e5a32e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check brain masks to catch really wacky co-reg - like dice of brain masks or something\n",
    "#visualize"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3.10 (nimlab 2023-11-06)",
   "language": "python",
   "name": "nimlab_py310_2023_11"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
